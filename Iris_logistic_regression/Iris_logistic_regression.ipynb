{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "noted-snowboard",
   "metadata": {},
   "source": [
    "# Iris species classification challenge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-birmingham",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "armed-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import statistics as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-devon",
   "metadata": {},
   "source": [
    "## Import csv\n",
    "We are using a different db compared to the one available in the kaggle challenge. This database has been made dirty on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acquired-function",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'iris_dirty.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4ac17cdcb1d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iris_dirty.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/excondables/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/excondables/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/excondables/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/excondables/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/excondables/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/excondables/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/excondables/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'iris_dirty.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('iris_dirty.csv', header = None) \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can already see that the col names are not correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-princeton",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-shark",
   "metadata": {},
   "source": [
    "### Change columns headers\n",
    "the columns header are caps lock and it need to be adapted to work with them in smoother way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the cols headers\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of new cols name\n",
    "col_names = [ 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "#substituting the cols names\n",
    "df.columns = col_names\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-contract",
   "metadata": {},
   "source": [
    "### Change petalwidth col type from object to float 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['petalwidthcm'] = df['petalwidthcm'].str.extract('(\\d+)')\n",
    "#extract using regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['petalwidthcm'] = df['petalwidthcm'].astype('float64')\n",
    "#convert from obj to float \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['petalwidthcm'] = df['petalwidthcm'].div(10)\n",
    "#adapt the scale from mm to cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-leonard",
   "metadata": {},
   "source": [
    "## EDA - exploratory data analysis - get to know the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-reduction",
   "metadata": {},
   "source": [
    "### Remove the 'mm' from the col obs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i want to see the means etc \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['5.1'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-green",
   "metadata": {},
   "source": [
    "### Replacing the mispelled obs.\n",
    "One of the iris setosa is mispelled and we need to replace it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the misspelling\n",
    "df['species'].replace({'Iris-setsoa' : 'Iris-setosa'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for na's\n",
    "missingdata=df.isna()\n",
    "missingdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the missing value in spealwidthcm\n",
    "df['sepalwidthcm'].fillna((df['sepalwidthcm'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-convertible",
   "metadata": {},
   "source": [
    "### Plot outliers and deal with these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize = (15,20));\n",
    "plt.show()\n",
    "#sepallength cm has outlier to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['petallengthcm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df.species);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(df, hue=\"species\", size=5).map(plt.scatter, \"sepallengthcm\", \"sepalwidthcm\").add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "violincols=[\"sepallengthcm\",\"sepalwidthcm\",\"petallengthcm\",\"petalwidthcm\"]\n",
    "for i in violincols:\n",
    "    sns.factorplot(x=\"species\",y=i,data=df,kind=\"violin\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for multicollinearity \n",
    "corr_matrix=df.corr(method='pearson')  # default\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax = sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all expected multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the ouliers from sepallength\n",
    "#remove outliers using calculated IQRs \n",
    "# first i define the percentiles\n",
    "\n",
    "iqr = np.percentile(df['sepallengthcm'],75) - np.percentile(df['sepallengthcm'],25)\n",
    "upper_limit = np.percentile(df['sepallengthcm'],75) + 1.5*iqr\n",
    "lower_limit = np.percentile(df['sepallengthcm'],25) - 1.5*iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['sepallengthcm']>lower_limit) & (df['sepallengthcm']<upper_limit)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize = (15,20));\n",
    "plt.show()\n",
    "#sepallength cm has outlier to remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-winning",
   "metadata": {},
   "source": [
    "## Split the data into train and test¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "#devide the target from the other dep. vars \n",
    "y= df['species']\n",
    "X=df.drop(['species'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size= 0.45, random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-bubble",
   "metadata": {},
   "source": [
    "## apply model and train model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = LogisticRegression(random_state=0, solver='lbfgs',max_iter=400,\n",
    "                  multi_class='ovr').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-conference",
   "metadata": {},
   "source": [
    "## evaluate accuracy and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "predictions = classification.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "standard-device",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "judicial-cleveland",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fb88af255e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# now we the st the model \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "accuracy_score(y_test,predictions)\n",
    "confusion_matrix(y_test,predictions)\n",
    "plot_confusion_matrix(classification, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-treasure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
